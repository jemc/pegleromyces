
BasicSpec {
  name: "String::Parser"
  
  new_parser: String::Parser.new
  
  [tests]
  
  it "can match from a tiny grammar": {
    parser = new_parser
    parser.grammar = Grammar {
      [rules]
      rule root:
        str('abc') / str('x') + set('Yy') + !str('y') + !!range('a','z') + any
    }
    state = parser.parse('xyz')
    assert_equal(state.end_idx, 3)
  }
  
  it "can match from a grammar with multiplicit patterns": {
    parser = new_parser
    parser.grammar = Grammar {
      [rules]
      rule root: str('x').+ + str('y').* + str('z').-
    }
    state = parser.parse('xxz')
    assert_equal(state.end_idx, 3)
  }
  
  it "can match from a grammar with rule calls": {
    parser = new_parser
    parser.grammar = Grammar {
      [rules]
      rule root: unintended / intended
      rule unintended: abc
      rule intended: x + any_y + not_y + any_lower
      
      rule abc:   str('abc')
      rule x:     str('x')
      rule any_y: set('Yy')
      rule not_y: !str('y')
      rule lower: range('a','z')
      rule any_lower: !!lower + any
    }
    state = parser.parse('xyz')
    assert_equal(state.end_idx, 3)
  }
  
  it "skips memoized rule calls without result corruption": {
    parser = new_parser
    parser.grammar = Grammar {
      [rules]
      rule root: moot
      rule moot:
        (array[:root] + str('NO')) / (array[:root] + str('NOPE')) / array[:root]
      rule array:
        r(str('[').token(:foo)[:t0] + (!str(']') + any).*[:list] + str(']'))
          { [:array, t0.line, *list.map(&:to_sym)] }
    }
    state = parser.parse('[abc]')
    assert(state.end_idx)
    assert_equal(state.result[:root], [:array, 1, :a, :b, :c])
  }
  
  it "can save a parser to a file to load and run it later": {
    parser = new_parser
    parser.grammar = Grammar {
      [rules]
      rule root: (r(character.+[:clist]) { clist })[:root]
      rule character: r(any[:text]) { text.to_sym }
    }
    state = parser.parse('xyz')
    assert_equal(state.result.fetch(:root), [:x, :y, :z])
    parser.save_prototype("/tmp/pegleromyces_output.my.rbc")
    
    parser = new_parser
    parser.load_prototype("/tmp/pegleromyces_output.my.rbc")
    state = parser.parse('xyz')
    assert_equal(state.result.fetch(:root), [:x, :y, :z])
  }
  
  it "can tokenize matches using a custom tokenizer function": {
    parser = new_parser
    parser.grammar = Grammar {
      tokenizer: &|type, source, start, stop| {
        token = [type, source.slice(start, stop - start)]
      }
      character: any.token(:char)
      [rules]
      rule root: (r(character.+[:clist]) { clist })[:root]
    }
    state = parser.parse('xyz')
    assert_equal(state.result.fetch(:root), [
      [:char, "x"], [:char, "y"], [:char, "z"]
    ])
  }
}
